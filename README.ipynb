{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./sample_output.png \"Sample Output\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolutional Neural Networks for Dog Breed Identification\n",
    "\n",
    "### Juan E. Rolon, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"sample_output.png\"\n",
    "     alt=\"sample_output\"\n",
    "     style=\"float: left; margin-right: 10px; width: 250px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Project overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this project, I implemented a real-world application of _Convolutional Neural Networks (CNNs)_ to develop an image classifier. This project was submitted as part of the requisites required to obtain **Machine Learning** Engineer Nanodegree from Udacity. It also forms part of the **Artificial Intelligence** curriculum.\n",
    "\n",
    "The project requires building a pipeline that can be used within a web or mobile application to process real-world, user-supplied images.  Given an image of a dog, the algorithm indetifies the type of breed associated to the image. The classifier is also capable of identifying a resembling dog breed when supplied with images of humans or closely related animals. \n",
    "\n",
    "Along with exploring state-of-the-art convolutional neural networks classification models, this project deals with important design decisions of image classifiers, and challenges involved in piecing together a series of models designed to perform various tasks in a data processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Required Libraries \n",
    "- Sklearn \n",
    "- Tensorflow with GPU support\n",
    "- OpenCV\n",
    "- Keras  \n",
    "- Imbalanced-learn\n",
    "- Feather format   \n",
    "\n",
    "#### Git Cloning and Datasets Downloading   \n",
    "\n",
    "\n",
    "1. Clone the following repository to obtain the required datasets.\n",
    "\t\n",
    "\t```\t\n",
    "\t\tgit clone https://github.com/juanerolon/convolutional-neural-networks.git\n",
    "\t```\n",
    "2. Download the [dog dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip).  Unzip the folder and place it in the repo, at location `path/to/dog-project/dogImages`. \n",
    "3. Download the [human dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip).  Unzip the folder and place it in the repo, at location `path/to/dog-project/lfw`.  If you are using a Windows machine, you are encouraged to use [7zip](http://www.7-zip.org/) to extract the folder. \n",
    "4. Donwload the [VGG-16 bottleneck features](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogVGG16Data.npz) for the dog dataset.  Place it in the repo, at location `path/to/dog-project/bottleneck_features`.\n",
    "5. Obtain the necessary Python packages, and switch Keras backend to Tensorflow.  \n",
    "\t\n",
    "\tFor __Mac/OSX__:\n",
    "\t```\n",
    "\t\tconda env create -f requirements/aind-dog-mac.yml\n",
    "\t\tsource activate aind-dog\n",
    "\t\tKERAS_BACKEND=tensorflow python -c \"from keras import backend\"\n",
    "\t```\n",
    "\n",
    "\tFor __Linux__:\n",
    "\t```\n",
    "\t\tconda env create -f requirements/aind-dog-linux.yml\n",
    "\t\tsource activate aind-dog\n",
    "\t\tKERAS_BACKEND=tensorflow python -c \"from keras import backend\"\n",
    "\t```\n",
    "\n",
    "\tFor __Windows__:\n",
    "\t```\n",
    "\t\tconda env create -f requirements/aind-dog-windows.yml\n",
    "\t\tactivate aind-dog\n",
    "\t\tset KERAS_BACKEND=tensorflow\n",
    "\t\tpython -c \"from keras import backend\"\n",
    "\t```\n",
    "6. Open the notebook in the present repositry and follow along.\n",
    "\t\n",
    "\t```\n",
    "\t\tjupyter notebook dog_app.ipynb\n",
    "\t```\n",
    "    \n",
    "#### Infrastructure required\n",
    "\n",
    "Your model can be trained on a local CPU-GPU, or if needed on an Amazon Web Services EC2 GPU instance.  Please refer to the following instructions for setting up a GPU instance for this project.  ([link for AIND students](https://classroom.udacity.com/nanodegrees/nd889/parts/16cf5df5-73f0-4afa-93a9-de5974257236/modules/53b2a19e-4e29-4ae7-aaf2-33d195dbdeba/lessons/2df3b94c-4f09-476a-8397-e8841b147f84/project), [link for MLND students](https://classroom.udacity.com/nanodegrees/nd009/parts/99115afc-e849-48cf-a580-cb22eea2ba1b/modules/777db663-2b0d-4040-9ae4-bf8c6ab8f157/lessons/a088c519-05af-4589-a1e2-2c484b1268ef/project))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You need an IDE capable of editing and running Ipython notebooks. If Jupyter is installed in your distribution:   \n",
    "\n",
    "`$ jupyter notebook cnn-image-classifier.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Project Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Step 1: Detect Humans\n",
    "\n",
    "| Criteria       \t\t|    Procedure\t        \t\t\t            | \n",
    "|:---------------------:|:---------------------------------------------------------:| \n",
    "| __1:__ Assess the Human Face Detector |  Obtain the percentage of the first 100 images in the dog and human face datasets with a detected human face.          |\n",
    "| __2:__ Assess the Human Face Detector |  Assess whether Haar cascades for face detection are an appropriate technique for human detection.    |\n",
    "\n",
    "#### Step 2: Detect Dogs\n",
    "\n",
    "| Criteria       \t\t|     Proceduer\t        \t\t\t            | \n",
    "|:---------------------:|:---------------------------------------------------------:| \n",
    "| __3:__ Assess the Dog Detector |  Obtain the percentage of the first 100 images in the dog and human face datasets with a detected dog.          |\n",
    "\n",
    "#### Step 3: Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "\n",
    "| Criteria       \t\t|     Procedure\t        \t\t\t            | \n",
    "|:---------------------:|:---------------------------------------------------------:| \n",
    "| Model Architecture | Select a CNN architecture. |\n",
    "| Train the Model | Obtain the number of epochs used to train the algorithm. |\n",
    "| Test the Model | Optimize model to obtain at least 1% accuracy on the test set. |\n",
    "\n",
    "\n",
    "#### Step 5: Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "| Criteria       \t\t|     Procedure\t        \t\t\t            | \n",
    "|:---------------------:|:---------------------------------------------------------:| \n",
    "| Obtain Bottleneck Features | Download the bottleneck features corresponding to one of the Keras pre-trained models (VGG-19, ResNet-50, Inception, or Xception). |\n",
    "| Model Architecture | Select a model architecture.  |\n",
    "|Model Architecture | Assess whether the chosen architecture succeeds in the classification task.  |\n",
    "| Compile the Model | Compile the cnn architecture by specifying the loss function and optimizer. |\n",
    "| Train the Model    | Implement a checkpointing procedure to train the model to select the model with the best validation loss. |\n",
    "| Load the Model with the Best Validation Loss    | Load the model weights that attained the least validation loss. |\n",
    "| Test the Model    | Obtain an accuracy on the test set at least of 60% or greater. |\n",
    "| Predict Dog Breed with the Model | Implement a function that takes a file path to an image as input and returns the dog breed that is predicted by the CNN. |\n",
    "\n",
    "\n",
    "#### Step 6: Test Algorithm\n",
    "\n",
    "| Criteria       \t\t|     Procedure\t        \t\t\t            | \n",
    "|:---------------------:|:---------------------------------------------------------:| \n",
    "| Test Algorithm   | Use the CNN from Step 5 to detect dog breed.  Assess whether output for each detected image type (dog, human, other) is different from previous cases. Obtain either predicted actual (or resembling) dog breed. |\n",
    "\n",
    "#### Step 7: Test your Algorithm\n",
    "| Criteria       \t\t|     Procedure\t        \t\t\t            | \n",
    "|:---------------------:|:---------------------------------------------------------:| \n",
    "| Test Algorithm on Sample Images   | Test at least 6 images, including at least two human and two dog images. |\n",
    "| Test Algorithm on Sample Images | Assess performance of the algorithm and at least three possible points of improvement. |\n",
    "\n",
    "## Further Tests and Improvements\n",
    "\n",
    "\n",
    "#### (1) Augment the Training Data \n",
    "\n",
    "[Augmenting the training and/or validation set](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) might help improve model performance. \n",
    "\n",
    "#### (2) Turn your Algorithm into a Web App\n",
    "\n",
    "Turn code into a web app using [Flask](http://flask.pocoo.org/) or [web.py](http://webpy.org/docs/0.3/tutorial)!  \n",
    "\n",
    "#### (3) Overlay Dog Ears on Detected Human Heads\n",
    "\n",
    "Overlay a Snapchat-like filter with dog ears on detected human heads.  Determine where to place the ears through the use of the OpenCV face detector, which returns a bounding box for the face.  It is also possible to overlay a dog nose filter, some nice tutorials for facial keypoints detection exist [here](https://www.kaggle.com/c/facial-keypoints-detection/details/deep-learning-tutorial).\n",
    "\n",
    "#### (4) Add Functionality for Dog Mutts\n",
    "\n",
    "Currently, if a dog appears 51% German Shepherd and 49% poodle, only the German Shephard breed is returned.  The algorithm may fail for every mixed breed dog.  Of course, if a dog is predicted as 99.5% Labrador, it is still worthwhile to round this to 100% and return a single breed; so, you will have to find a nice balance.  \n",
    "\n",
    "#### (5) Experiment with Multiple Dog/Human Detectors\n",
    "\n",
    "Perform a systematic evaluation of various methods for detecting humans and dogs in images.  Provide improved methodology for the `face_detector` and `dog_detector` functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## License\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The present project constitutes intellectual work towards completion of Udacitys Machine Learning Engineer Nanodegree. You are free to modify and adapt the code to your needs, but please avoid using an exact copy of this work as your own to obtain credits towards any educational platform, doing so may imply plagiarism on your part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
